# Sprint Review

## What is a Sprint Review?

The Sprint Review is a collaborative meeting held at the end of each sprint where the team demonstrates completed work to stakeholders and gathers feedback. It's an opportunity to inspect the increment and adapt the Product Backlog if needed.

## Sprint Review Overview

- **Duration**: 1-2 hours for a 2-week sprint
- **Timing**: End of the sprint, before the retrospective
- **Participants**: Scrum Team, stakeholders, customers, management
- **Format**: Informal demonstration and discussion
- **Outcome**: Feedback and updated Product Backlog

## Sprint Review Agenda

### 1. Introduction (5 minutes)
- Welcome attendees
- Review Sprint Goal
- Overview of what was planned vs. completed

### 2. Demo Completed Work (45-60 minutes)
- Team demonstrates working software
- Show only "Done" items that meet Definition of Done
- Focus on functionality, not code
- Interactive - let stakeholders try features

### 3. Discuss What Didn't Get Done (10 minutes)
- Review incomplete items
- Explain reasons (not to blame, but to learn)
- Discuss implications for future sprints

### 4. Review Product Backlog (15 minutes)
- Product Owner discusses current backlog status
- Projected completion timeline based on progress
- Upcoming priorities

### 5. Gather Feedback (20 minutes)
- Stakeholders provide input on demonstrated work
- Discussion of market changes or new requirements
- Identify adjustments needed for next sprint

### 6. Next Steps (10 minutes)
- Summarize feedback and action items
- Preview next sprint goals
- Thank participants

## Best Practices

1. **Prepare thoroughly**: Ensure all demos work before the meeting
2. **Focus on working software**: No PowerPoint presentations
3. **Tell a story**: Connect features to user value
4. **Encourage interaction**: Let stakeholders use the product
5. **Be transparent**: Show both successes and challenges
6. **Timebox demonstrations**: Don't get stuck on one item
7. **Capture feedback**: Take notes for backlog refinement
8. **Celebrate achievements**: Recognize team accomplishments

## What to Demonstrate

âœ… **DO demonstrate:**
- Completed user stories that meet DoD
- Working features in realistic scenarios
- User interface and user experience
- Integration between components
- Performance improvements

âŒ **DON'T demonstrate:**
- Incomplete work or work in progress
- Code or architecture (unless asked)
- Testing environments or test data issues
- Internal technical debt items
- Work not related to sprint goal

## Demonstration Techniques

### Live Demo
Show the actual working software in a production-like environment.

**Pros:**
- Most authentic experience
- Shows real performance
- Builds stakeholder confidence

**Cons:**
- Risk of technical issues
- Requires stable environment

### Recorded Demo
Pre-record demonstrations with narration.

**Pros:**
- No risk of technical problems
- Can be polished and edited
- Reusable for absent stakeholders

**Cons:**
- Less interactive
- Can't adapt to questions easily

### Hybrid Approach
Prepare recordings as backup, attempt live demo first.

## Handling Feedback

### Types of Feedback

1. **Acceptance**: "This looks great, exactly what we needed!"
   - âœ… Mark story as complete
   - ğŸ“ Note success patterns

2. **Refinement**: "Can we adjust the button placement?"
   - ğŸ“‹ Create new story or task
   - ğŸ”„ Add to backlog for prioritization

3. **Rejection**: "This isn't what we wanted at all"
   - ğŸ¤” Understand the gap
   - ğŸ“ Update or rewrite story
   - ğŸ”„ Re-prioritize in backlog

4. **New Ideas**: "What if we also added...?"
   - ğŸ’¡ Capture as new story
   - ğŸ“Š Product Owner prioritizes later

### Feedback Best Practices

- ğŸ¯ Stay focused on sprint work
- âœï¸ Write everything down
- ğŸ™ Thank people for input
- â° Timebox discussions
- ğŸ”„ Follow up after meeting

## Common Pitfalls

- âŒ **No working software**: Only showing slides or plans
- âŒ **Unprepared demos**: Technical issues waste time
- âŒ **Defensive attitude**: Getting upset about feedback
- âŒ **Too technical**: Losing stakeholders in details
- âŒ **No stakeholders**: Missing the key audience
- âŒ **Too long**: Exceeding the timebox
- âŒ **No interaction**: Just presenting, not collaborating

## Metrics to Share

Consider sharing these sprint metrics:

- **Velocity**: Story points completed
- **Burndown**: Work remaining over time
- **Sprint Goal Achievement**: Met or not met
- **Quality Metrics**: Bug counts, test coverage
- **Team Capacity**: Availability vs. actual hours

## Remote Sprint Review Tips

For distributed teams:

- ğŸ¥ Use high-quality video conferencing
- ğŸ–¥ï¸ Share screen for demonstrations
- ğŸ’¬ Use chat for questions during demo
- ğŸ¬ Consider recording the session
- ğŸ“§ Send summary and recording afterward
- â±ï¸ Be extra mindful of time zones
- ğŸ”— Share demo links ahead of time

## Sprint Review vs. Sprint Retrospective

| Sprint Review | Sprint Retrospective |
|--------------|---------------------|
| External focus (product) | Internal focus (process) |
| Includes stakeholders | Team only |
| Demo working software | Discuss how team worked |
| Adapt product backlog | Adapt team practices |
| End of sprint | After review |

## Success Indicators

A successful Sprint Review includes:

- âœ… All planned attendees participate
- âœ… Working software is demonstrated
- âœ… Stakeholders provide meaningful feedback
- âœ… Product Backlog is updated based on input
- âœ… Team feels proud of accomplishments
- âœ… Clear understanding of next steps
- âœ… Meeting stays within timebox

---

[â† Back to Home](../README.md)
